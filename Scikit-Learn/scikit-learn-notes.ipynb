{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import set_config\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides notes for common classes and methods used in scikit-learn. It also answers questions to concepts I had trouble understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(120, 4)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "rng = np.random.RandomState(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rng)\n",
    "print(X.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:** An estimator is any object in scikit-learn that learns from data by calling `fit()`.\n",
    "\n",
    "*   It can be a transformer (e.g., `StandardScaler`), a predictor (e.g., `LogisticRegression`), or both.\n",
    "*   Essentially, if an object has a `fit()` method, it's an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()  # Estimator\n",
    "model = LogisticRegression()  # Estimator\n",
    "\n",
    "scaler.fit(X_train)  # ✅ Works because StandardScaler is an estimator\n",
    "model.fit(X_train, y_train)  # ✅ Works because LogisticRegression is an estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:** A transformer is a special type of estimator that modifies data by calling `transform()`.\n",
    "\n",
    "*   Transformers are used for preprocessing (scaling, encoding, feature selection, etc.).\n",
    "*   They learn something from `fit()` and apply it with `transform()`.\n",
    "*   Many transformers also support `fit_transform()` to do both in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder()\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "scaler.fit(X_train)  # ✅ Learns mean & std\n",
    "X_scaled = scaler.transform(X_train)  # ✅ Applies scaling\n",
    "\n",
    "X_scaled = scaler.fit_transform(X_train)  # ✅ Shortcut (fit + transform)\n",
    "\n",
    "pca.fit(X_train)  # ✅ Learns principal components\n",
    "X_pca = pca.transform(X_train)  # ✅ Applies dimensionality reduction\n",
    "X_pca = pca.fit_transform(X_train)  # ✅ Shortcut (fit + transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rule:** If an object has both `fit()` and `transform()`, it's a transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:** A predictor is an estimator that makes predictions by calling `predict()`.\n",
    "\n",
    "*   Predictors are models that take input data and output predictions.\n",
    "*   Some predictors also support `predict_proba()` for probability estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()  # Predictor\n",
    "rf = RandomForestClassifier()  # Predictor\n",
    "\n",
    "clf.fit(X_train, y_train)  # ✅ Learns from data\n",
    "y_pred = clf.predict(X_test)  # ✅ Makes predictions\n",
    "\n",
    "rf.fit(X_train, y_train)  # ✅ Learns from data\n",
    "y_prob = rf.predict_proba(X_test)  # ✅ Outputs class probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rule:** If an object has `predict()`, it's a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64) (360, 64)\n",
      "(1437,) (360,)\n",
      "False\n",
      "\n",
      "Best Estimator:\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 SGDClassifier(alpha=3e-05, penalty='l1',\n",
      "                               random_state=RandomState(MT19937) at 0x19CBAB0B040))])\n",
      "Best Params:\n",
      "{'model__alpha': 3e-05, 'model__penalty': 'l1'} \n",
      "Best score:\n",
      "0.9547724586288416\n",
      "\n",
      "CV Results\n",
      "\n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.053779      0.007294         0.001734        0.000629   \n",
      "1        0.132930      0.017408         0.001267        0.000442   \n",
      "2        0.133864      0.014382         0.001300        0.000458   \n",
      "3        0.040809      0.005264         0.001267        0.000442   \n",
      "4        0.102590      0.009971         0.001267        0.000442   \n",
      "5        0.100923      0.013238         0.001434        0.000496   \n",
      "6        0.043910      0.005017         0.001300        0.000458   \n",
      "7        0.106657      0.011577         0.001300        0.000458   \n",
      "8        0.123061      0.017200         0.001367        0.000482   \n",
      "9        0.041776      0.005813         0.001267        0.000442   \n",
      "10       0.099756      0.019359         0.001034        0.000315   \n",
      "11       0.098656      0.018636         0.000834        0.000373   \n",
      "\n",
      "    param_model__alpha param_model__penalty  \\\n",
      "0              0.00010                   l2   \n",
      "1              0.00010                   l1   \n",
      "2              0.00010           elasticnet   \n",
      "3              0.00003                   l2   \n",
      "4              0.00003                   l1   \n",
      "5              0.00003           elasticnet   \n",
      "6              0.00005                   l2   \n",
      "7              0.00005                   l1   \n",
      "8              0.00005           elasticnet   \n",
      "9              0.00007                   l2   \n",
      "10             0.00007                   l1   \n",
      "11             0.00007           elasticnet   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0    {'model__alpha': 0.0001, 'model__penalty': 'l2'}           0.979167   \n",
      "1    {'model__alpha': 0.0001, 'model__penalty': 'l1'}           0.937500   \n",
      "2   {'model__alpha': 0.0001, 'model__penalty': 'el...           0.979167   \n",
      "3     {'model__alpha': 3e-05, 'model__penalty': 'l2'}           0.958333   \n",
      "4     {'model__alpha': 3e-05, 'model__penalty': 'l1'}           0.958333   \n",
      "5   {'model__alpha': 3e-05, 'model__penalty': 'ela...           0.937500   \n",
      "6     {'model__alpha': 5e-05, 'model__penalty': 'l2'}           0.979167   \n",
      "7     {'model__alpha': 5e-05, 'model__penalty': 'l1'}           0.958333   \n",
      "8   {'model__alpha': 5e-05, 'model__penalty': 'ela...           0.979167   \n",
      "9     {'model__alpha': 7e-05, 'model__penalty': 'l2'}           0.958333   \n",
      "10    {'model__alpha': 7e-05, 'model__penalty': 'l1'}           0.958333   \n",
      "11  {'model__alpha': 7e-05, 'model__penalty': 'ela...           0.979167   \n",
      "\n",
      "    split1_test_score  split2_test_score  ...  split23_test_score  \\\n",
      "0            0.937500           0.895833  ...            0.979167   \n",
      "1            0.916667           0.916667  ...            0.916667   \n",
      "2            0.895833           0.895833  ...            1.000000   \n",
      "3            0.875000           0.875000  ...            1.000000   \n",
      "4            0.916667           0.937500  ...            0.937500   \n",
      "5            0.895833           0.916667  ...            0.979167   \n",
      "6            0.937500           0.895833  ...            1.000000   \n",
      "7            0.895833           0.895833  ...            0.937500   \n",
      "8            0.916667           0.895833  ...            0.958333   \n",
      "9            0.937500           0.937500  ...            1.000000   \n",
      "10           0.916667           0.875000  ...            0.937500   \n",
      "11           0.895833           0.916667  ...            0.958333   \n",
      "\n",
      "    split24_test_score  split25_test_score  split26_test_score  \\\n",
      "0             0.979167            0.979167            0.937500   \n",
      "1             0.958333            0.958333            0.916667   \n",
      "2             0.979167            0.958333            0.937500   \n",
      "3             0.979167            0.979167            0.958333   \n",
      "4             1.000000            0.958333            0.916667   \n",
      "5             0.979167            0.979167            0.958333   \n",
      "6             0.979167            0.958333            0.937500   \n",
      "7             0.958333            0.958333            0.958333   \n",
      "8             0.979167            0.979167            0.958333   \n",
      "9             0.979167            0.958333            0.937500   \n",
      "10            0.958333            0.958333            0.958333   \n",
      "11            0.979167            0.979167            0.937500   \n",
      "\n",
      "    split27_test_score  split28_test_score  split29_test_score  \\\n",
      "0             0.936170            0.978723            0.957447   \n",
      "1             0.957447            1.000000            0.978723   \n",
      "2             0.936170            0.978723            0.914894   \n",
      "3             0.936170            0.957447            0.914894   \n",
      "4             0.957447            0.978723            0.936170   \n",
      "5             0.957447            0.978723            0.936170   \n",
      "6             0.936170            0.978723            0.957447   \n",
      "7             0.957447            1.000000            0.957447   \n",
      "8             0.957447            0.978723            0.936170   \n",
      "9             0.936170            0.978723            0.914894   \n",
      "10            0.957447            1.000000            0.957447   \n",
      "11            0.957447            0.978723            0.957447   \n",
      "\n",
      "    mean_test_score  std_test_score  rank_test_score  \n",
      "0          0.952689        0.022143                9  \n",
      "1          0.953428        0.028791                5  \n",
      "2          0.950576        0.026153               10  \n",
      "3          0.949867        0.029346               11  \n",
      "4          0.954772        0.024713                1  \n",
      "5          0.953384        0.022630                6  \n",
      "6          0.954078        0.023086                3  \n",
      "7          0.954108        0.030135                2  \n",
      "8          0.954078        0.024307                3  \n",
      "9          0.947798        0.021438               12  \n",
      "10         0.952719        0.028924                7  \n",
      "11         0.952704        0.020044                8  \n",
      "\n",
      "[12 rows x 40 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>target_digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1     2     3     4     5    6    7    8    9  ...   55   56  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  0.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  0.0  0.0   \n",
       "\n",
       "       57   58    59    60    61   62   63  target_digit  \n",
       "0     0.0  6.0  13.0  10.0   0.0  0.0  0.0             0  \n",
       "1     0.0  0.0  11.0  16.0  10.0  0.0  0.0             1  \n",
       "2     0.0  0.0   3.0  11.0  16.0  9.0  0.0             2  \n",
       "3     0.0  7.0  13.0  13.0   9.0  0.0  0.0             3  \n",
       "4     0.0  0.0   2.0  16.0   4.0  0.0  0.0             4  \n",
       "...   ...  ...   ...   ...   ...  ...  ...           ...  \n",
       "1792  0.0  2.0  14.0  15.0   9.0  0.0  0.0             9  \n",
       "1793  0.0  6.0  16.0  14.0   6.0  0.0  0.0             0  \n",
       "1794  0.0  2.0   9.0  13.0   6.0  0.0  0.0             8  \n",
       "1795  0.0  5.0  12.0  16.0  12.0  0.0  0.0             9  \n",
       "1796  1.0  8.0  12.0  14.0  12.0  1.0  0.0             8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "df = pd.DataFrame(X)\n",
    "df['target_digit'] = y\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=rng)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "duplicates = [np.any(np.all(row == X_train, axis=1)) for row in X_test]\n",
    "print(np.any(duplicates))  # Should be False\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', SGDClassifier(random_state=rng))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {'model__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'model__alpha': [0.0001, 0.00003, 0.00005, 0.00007]}\n",
    "]\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "# # training set\n",
    "# y_pred_train = pipe.predict(X_train)\n",
    "# y_pred_train_score = classification_report(y_train, y_pred_train) \n",
    "# # test set\n",
    "# y_pred = pipe.predict(X_test)\n",
    "# y_score = classification_report(y_test, y_pred)\n",
    "# print(f\"Score on train set:\\n{y_pred_train_score}\\n\\nScore on test data\\n{y_score}\")\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=30, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest Estimator:\\n{grid.best_estimator_}\\nBest Params:\\n{grid.best_params_} \\nBest score:\\n{grid.best_score_}\\n\\nCV Results\\n\\n{pd.DataFrame(grid.cv_results_)}\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.91      0.89      0.90        35\n",
      "           2       0.94      0.94      0.94        36\n",
      "           3       0.96      0.93      0.95        29\n",
      "           4       0.91      0.97      0.94        30\n",
      "           5       0.93      0.95      0.94        40\n",
      "           6       1.00      0.95      0.98        44\n",
      "           7       0.90      0.97      0.94        39\n",
      "           8       0.87      0.85      0.86        39\n",
      "           9       0.95      0.93      0.94        41\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.94      0.94      0.94       360\n",
      "weighted avg       0.94      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94791667 0.95138889 0.96167247 0.94425087 0.96167247]\n",
      "\n",
      "Avg accuracy: \n",
      " 0.9533802748741772\n"
     ]
    }
   ],
   "source": [
    "cv_score = cross_val_score(grid.best_estimator_, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(cv_score)\n",
    "print('\\nAvg accuracy: \\n', cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Order\n",
    "**Question**: So when predictions = `pipe.predict(X_test)` is called, is it taking the scaler into account?\n",
    "- Yes! ✅ When you call: predictions = pipe.predict(X_test), the entire pipeline is applied, meaning both the scaler and the classifier are used.\n",
    "\n",
    "When you call `pipe.predict(X_test)`, the pipeline follows these steps in order:\n",
    "\n",
    "1.  **`StandardScaler` transforms `X_test`:**\n",
    "    The raw test data (`X_test`) is scaled using the `MinMaxScaler` that was already fitted on `X_train`.\n",
    "\n",
    "2.  **`SGDClassifier` makes predictions on the scaled data:**\n",
    "    The classifier (`SGDClassifier`) receives the transformed data and makes predictions.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Param Grid Syntax\n",
    "syntax is :\n",
    "\n",
    "*estimator*__*parameter* (estimator, two underscores, parameter)\n",
    "\n",
    "**Question**: What is the difference (using above pipeline's example) between\n",
    "\n",
    "```\n",
    "param_grid = [\n",
    "    {'model__penalty': ['l2', 'l1', 'elasticnet']},\n",
    "    {'model__alpha': [0.0001, 0.001, 0.01, 0.1]}\n",
    "]\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```\n",
    "param_grid = {\n",
    "    'model__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'model__alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this has TWO different grids (there is a list of dictionaries)\n",
    "param_grid = [\n",
    "    {'model__penalty': ['l2', 'l1', 'elasticnet']}, #grid 1\n",
    "    {'model__alpha': [0.0001, 0.001, 0.01, 0.1]} #grid 2\n",
    "]\n",
    "\n",
    "# this is ONE grid (one dictionary)\n",
    "param_grid = {\n",
    "    'model__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'model__alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **first** param_grid will **NOT** consider all combinations of `penalty` and `alpha`, `GridSearchCV` treats them as two separate independent grids.\n",
    "\n",
    "It will:\n",
    "\n",
    "- 1. Try tuning only `model__penalty` while keeping the default value for `model__alpha` (which is 0.0001).\n",
    "- 2. Then, it will try tuning only `model__alpha` while keeping the default value for `model__penalty` (which is 'l2').\n",
    "\n",
    "The **second** param_grid will **WILL** consider all combinations of `penalty` and `alpha`, `GridSearchCV` treats them as one grid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replaces NaNs with a strategy like mean, median, mode, or a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 7.5],\n",
       "       [4. , 5. , 6. ],\n",
       "       [7. , 8. , 9. ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "X_2 = np.array([[1, 2, np.nan], [4, np.nan, 6], [7, 8, 9]])\n",
    "imputer = SimpleImputer(strategy=\"mean\")  # Replace NaNs with column mean\n",
    "X_imputed = imputer.fit_transform(X_2)\n",
    "X_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimates missing values by predicting them based on other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 2.        , 3.00203274],\n",
       "       [4.        , 4.99796925, 6.        ],\n",
       "       [7.        , 8.        , 9.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer = IterativeImputer()\n",
    "X_imputed = imputer.fit_transform(X_2)\n",
    "X_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe Best Way - Pandas Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If two features have a correlation above a threshold (e.g., 0.9), drop one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 65)\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = df.corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with high correlation\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "# Drop highly correlated features\n",
    "df_reduced = df.drop(to_drop, axis=1)\n",
    "print(df.shape)\n",
    "print(df_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) reduces redundancy by transforming correlated features into a set of uncorrelated components.\n",
    "\n",
    "\n",
    "**1. To Reduce the Number of Features (Dimensionality Reduction)**\n",
    "\n",
    "*   If your dataset has many features (high dimensionality), PCA can help reduce the number while keeping most of the information.\n",
    "*   This is useful because high-dimensional data can lead to the curse of dimensionality, making models slower and more prone to overfitting.\n",
    "*   **📌 Use case:** You have a dataset with hundreds of features, but many are redundant or correlated. PCA helps compress the data.\n",
    "\n",
    "**2. To Handle Multicollinearity (Highly Correlated Features)**\n",
    "\n",
    "*   If features are highly correlated, models like linear regression and logistic regression may struggle.\n",
    "*   PCA creates new uncorrelated features (principal components), which can improve model performance.\n",
    "*   **📌 Use case:** You have a dataset with many correlated variables (e.g., stock prices, sensor data). PCA helps remove redundancy.\n",
    "\n",
    "**3. To Speed Up Training for Computational Efficiency**\n",
    "\n",
    "*   Some machine learning models (e.g., SVMs, k-NN) slow down with too many features.\n",
    "*   Reducing dimensions with PCA can make training and predictions faster.\n",
    "*   **📌 Use case:** You're working with image data (e.g., 64x64 pixels = 4,096 features per image). Reducing dimensions with PCA speeds up training.\n",
    "\n",
    "**4. To Visualize High-Dimensional Data**\n",
    "\n",
    "*   PCA can reduce a dataset from many dimensions to 2D or 3D, making it easier to plot and visualize patterns.\n",
    "*   This is often used in exploratory data analysis (EDA).\n",
    "*   **📌 Use case:** You want to visualize customer clusters in a 100-feature dataset. PCA helps reduce it to 2D for plotting.\n",
    "\n",
    "**5. To Denoise Data (Feature Compression)**\n",
    "\n",
    "*   PCA helps filter out small variations or noise by focusing on the most important components.\n",
    "*   It can be useful for image compression or removing noise from sensor data.\n",
    "*   **📌 Use case:** You're working with speech recognition or ECG signals with lots of noise. PCA helps keep only useful information.\n",
    "\n",
    "**When Should You NOT Use PCA?**\n",
    "\n",
    "*   **❌ When feature interpretability is important** – PCA transforms features into abstract components that are harder to interpret.\n",
    "*   **❌ When you have categorical features** – PCA only works with numerical data.\n",
    "*   **❌ When your model already handles correlated features well** – Some algorithms (e.g., tree-based models like Random Forests) don't need PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape\n",
      "(1437, 64)\n",
      "\n",
      "PCA\n",
      "[[ 23.37877851  -4.96617545]\n",
      " [-15.21542888 -15.48613197]\n",
      " [-21.04421107  -4.89824828]\n",
      " ...\n",
      " [  3.47676504  18.65116785]\n",
      " [  3.21484471  15.29047993]\n",
      " [ -4.29186733   2.59963173]]\n",
      "\n",
      "PCA Shape\n",
      "(1437, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)  # Reduce to 2 components\n",
    "\n",
    "print('X Train Shape')\n",
    "print(X_train.shape)\n",
    "\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "\n",
    "print('\\nPCA')\n",
    "print(X_pca)\n",
    "\n",
    "print('\\nPCA Shape')\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas vs PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method                                      | When to Use                                                                                                | Pros                                                                                                  | Cons                                                                                                               |\n",
    "| :------------------------------------------ | :--------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |\n",
    "| Pandas Correlation Matrix (Feature Dropping) | When you have redundant features that don't add much value.                                              | - Keeps interpretability (e.g., in regression models).<br> - Simple to implement.                       | - May remove useful features.<br> - Manual threshold selection (e.g., >0.9 correlation).                       |\n",
    "| PCA (Principal Component Analysis)         | When you want to reduce dimensionality but keep all information.                                            | - Keeps all data (just transforms it).<br> - Helps avoid multicollinearity.                           | - Harder to interpret (new features are combinations of old ones).<br> - Might lose small but important details. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to Use What?**\n",
    "\n",
    "*   **For regression models (like Linear Regression, Logistic Regression)** → Use the correlation matrix to drop features (because collinearity causes unstable coefficients).\n",
    "*   **For machine learning models like SVM, Random Forest, or Neural Networks** → PCA can be useful (since models don't require interpretability, and PCA can improve efficiency).\n",
    "*   **If you need high interpretability** → Feature dropping is better.\n",
    "*   **If dimensionality is too high and you don't care about feature meaning** → Use PCA.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "*   If you can afford to lose features, drop them using pandas correlation matrix.\n",
    "*   If you want to keep all information, use PCA, but be aware that transformed features are no longer in the original space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the estimator's built in Regularization / C / Penalty / Alpha .. etc parameter to adjust the Regularization. \n",
    "\n",
    "- Lasso Regression (L1 penalty) can shrink some feature coefficients to zero, effectively removing redundant ones.\n",
    "- Ridge Regression (L2 penalty) penalizes large coefficients, reducing their impact but not removing them completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template for Pipeline. Edit column transformer variable to edit the data columns needed; edit 'model' step in pipeline to be whichever estimator needed\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "# make_column_transformer takes Tuples of the form (transformer, columns); columns take [] if transformer expects 2D array, no brackets if it expects 1D array\n",
    "column_transformer = make_column_transformer([\n",
    "    (StandardScaler(), ['column name']),\n",
    "    (OneHotEncoder(), ['column name'])],\n",
    "    n_jobs=-1)\n",
    "\n",
    "# name of step, estimator\n",
    "pipeline = Pipeline([\n",
    "    ('column transformer', column_transformer),\n",
    "    ('imputer',SimpleImputer()),\n",
    "    ('feature reduction', PCA()),\n",
    "    ('model', SGDClassifier())\n",
    "])\n",
    "\n",
    "# parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "\n",
    "}\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=rng)\n",
    "\n",
    "grid = GridSearchCV(pipeline,\n",
    "                    param_grid=param_grid,\n",
    "                    n_jobs=-1,\n",
    "                    cv=5,\n",
    "                    return_train_score=True\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Never call fit() on test data\n",
    "- sklearn.preprocessing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
